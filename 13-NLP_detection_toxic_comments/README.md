
# Анализ токсичности комментариев при помощи модели BERT

## Описание проекта
Интернет-магазин запускает новый сервис: теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. 
<br>Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.

Необходимо обучить модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок.

Модель должна иметь значение метрики качества F1>=0.75.

## Этапы проекта
1. Загрузим и проанализируем соотношение классов
2. Создадим подвыборки
3. Проведем токенизацию и создадим эмбеддинги при помощи transformers на основе предобученной bert_toxic
4. Создадим и обучим модели с подбором параметров через GridSearchCV:
   -  логистической регрессии 
   -  дерева решений
   -  случайного леса
5. Проверим модель случайного леса на тестовой выборке и проанализируем модель на адекватность.
   
## Результат
Выбранная модель случайного леса была протестирована на тестовой выборке и показала результат **F1=0,963**

## Технические параметры среды
Библиотеки: pandas, numpy, torch, transformers, sklearn, matplotlib, seaborn, tqdm
<br>Версия Python: 3.9.5
